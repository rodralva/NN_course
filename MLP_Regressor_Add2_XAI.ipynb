{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_Regressor_Add2_XAI.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BFLRtTn1Lu-L",
        "3QGkp0AMLOI_"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8Rc1iIGlBXK"
      },
      "source": [
        "# Ejemplo de Red Completamente Conectada.\n",
        "Este es un ejemplo de Red Completamente Conectada (MLP) con objetivo pronósticar la suma de varios enteros y verificación de cuales son las variables más importantes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCkpuVJoLdxR"
      },
      "source": [
        "## Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpBMcQxaHKUF"
      },
      "source": [
        "from random import seed\n",
        "import random\n",
        "from random import randint, randrange"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEUzc8d0Jqs-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4ad7UB9iXeR"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k3Fue2Mk3EI"
      },
      "source": [
        "import scipy.stats\n",
        "from pylab import *"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjr4bgyVRoRE"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.layers import Dense, Dropout,Convolution1D, MaxPooling1D, Flatten\n",
        "from tensorflow.python.keras import Sequential, Input, Model\n",
        "from tensorflow import keras"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgEjIeujpDSl"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvFwqnphLlO_"
      },
      "source": [
        "## Fijar semilla del generador de números aleatorios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlyAtC9RLsSS"
      },
      "source": [
        "seed(1234)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFLRtTn1Lu-L"
      },
      "source": [
        "## Generados dos listas de números aleatorios y sumarlos.\n",
        "Además se generan otras dos listas de números. Una de ellas es la tercera lista con la adición o substracción de una unidad aleatoriamente, y la cuarta lista es de nuevo una lista aleatoria. En ningún caso, estos dos listas se utilizan en la suma. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ7m-QSJ9B3R"
      },
      "source": [
        "list_lenght=1000"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhkHcJzuHh3Y",
        "outputId": "7b94d127-3f9f-4d4c-f343-78ef3d900b51"
      },
      "source": [
        "randomList1 = []\n",
        "# Set a length of the list to 10\n",
        "for i in range(0, list_lenght):\n",
        "    # any random numbers from 0 to 10\n",
        "    randomList1.append(randint(0, 100))\n",
        "\n",
        "print(\"Primera lista\", randomList1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primera lista [47, 83, 38, 53, 76, 24, 15, 49, 23, 26, 30, 43, 30, 26, 58, 92, 69, 80, 73, 47, 50, 76, 37, 34, 38, 67, 11, 0, 75, 80, 3, 2, 19, 12, 65, 75, 81, 14, 71, 60, 46, 28, 81, 87, 13, 96, 12, 69, 95, 31, 89, 84, 45, 16, 41, 72, 56, 70, 56, 86, 44, 90, 83, 47, 49, 18, 85, 46, 98, 37, 38, 7, 67, 5, 47, 47, 15, 34, 10, 28, 4, 82, 89, 55, 78, 23, 50, 62, 55, 84, 0, 98, 90, 33, 21, 71, 68, 81, 52, 64, 85, 41, 1, 14, 3, 30, 12, 73, 19, 26, 96, 68, 64, 22, 56, 84, 8, 44, 24, 94, 15, 72, 2, 16, 2, 79, 67, 46, 98, 57, 55, 36, 88, 33, 42, 2, 87, 84, 35, 18, 76, 69, 81, 80, 8, 75, 15, 20, 16, 64, 61, 96, 83, 57, 49, 62, 57, 83, 27, 87, 35, 36, 84, 61, 28, 1, 11, 62, 17, 30, 38, 98, 25, 56, 24, 12, 76, 96, 8, 47, 87, 25, 21, 22, 45, 19, 41, 47, 36, 39, 17, 39, 59, 82, 37, 98, 87, 38, 8, 54, 17, 41, 47, 19, 43, 44, 35, 42, 20, 26, 89, 23, 2, 65, 89, 27, 78, 68, 91, 60, 3, 81, 47, 61, 63, 32, 13, 56, 48, 58, 94, 35, 57, 60, 83, 9, 60, 50, 51, 49, 71, 81, 4, 3, 88, 46, 94, 47, 63, 84, 5, 83, 72, 72, 63, 56, 14, 81, 99, 60, 8, 41, 33, 69, 88, 63, 17, 1, 1, 2, 51, 77, 52, 93, 14, 47, 75, 65, 29, 9, 96, 80, 50, 17, 31, 95, 74, 11, 34, 53, 89, 88, 24, 94, 95, 55, 53, 23, 58, 96, 16, 6, 81, 78, 57, 4, 46, 75, 6, 87, 18, 48, 39, 16, 98, 72, 46, 52, 40, 45, 2, 60, 20, 87, 74, 76, 58, 0, 42, 17, 49, 16, 48, 80, 81, 76, 95, 63, 49, 15, 25, 84, 25, 69, 50, 15, 84, 77, 46, 17, 0, 67, 37, 82, 30, 26, 60, 47, 67, 51, 37, 4, 37, 36, 80, 5, 54, 90, 63, 83, 76, 12, 33, 85, 4, 49, 46, 55, 99, 19, 47, 42, 48, 90, 48, 2, 35, 46, 33, 38, 97, 67, 46, 58, 37, 70, 34, 70, 41, 26, 10, 87, 24, 73, 12, 60, 1, 93, 51, 6, 18, 50, 45, 36, 89, 46, 43, 77, 55, 21, 30, 78, 97, 58, 35, 81, 51, 48, 94, 94, 2, 45, 63, 0, 95, 19, 5, 34, 26, 15, 6, 63, 84, 17, 80, 87, 84, 42, 26, 91, 97, 94, 85, 25, 44, 13, 45, 54, 75, 50, 94, 44, 88, 74, 76, 23, 10, 87, 55, 60, 83, 15, 30, 70, 37, 54, 75, 79, 56, 6, 53, 73, 97, 50, 74, 65, 46, 65, 5, 80, 2, 67, 63, 40, 24, 1, 67, 3, 65, 74, 22, 89, 13, 53, 47, 64, 12, 81, 19, 53, 93, 41, 89, 87, 56, 8, 14, 4, 92, 33, 53, 14, 91, 43, 28, 68, 70, 74, 88, 7, 47, 84, 28, 17, 61, 7, 55, 64, 31, 58, 49, 92, 27, 97, 30, 43, 65, 89, 48, 24, 97, 15, 3, 26, 71, 82, 47, 79, 67, 50, 51, 52, 49, 45, 43, 67, 5, 91, 34, 76, 52, 82, 65, 51, 57, 71, 57, 87, 18, 5, 23, 13, 59, 78, 26, 95, 21, 40, 16, 16, 67, 97, 95, 80, 16, 92, 46, 77, 68, 83, 20, 65, 56, 54, 40, 7, 17, 79, 43, 45, 39, 57, 13, 1, 79, 6, 21, 70, 32, 92, 98, 44, 36, 89, 46, 54, 22, 98, 49, 78, 53, 5, 72, 62, 54, 23, 82, 62, 35, 73, 62, 50, 81, 49, 89, 86, 11, 75, 57, 66, 33, 93, 93, 79, 91, 8, 87, 83, 72, 95, 53, 48, 77, 9, 9, 59, 52, 13, 5, 86, 77, 14, 51, 56, 75, 1, 39, 68, 81, 93, 14, 25, 95, 84, 67, 73, 78, 36, 28, 75, 63, 16, 53, 75, 20, 22, 54, 67, 72, 58, 59, 56, 72, 13, 37, 7, 9, 73, 64, 8, 36, 14, 92, 69, 53, 82, 62, 29, 70, 67, 64, 88, 17, 86, 26, 30, 48, 19, 7, 42, 75, 42, 85, 90, 12, 96, 72, 25, 88, 91, 59, 75, 49, 90, 44, 52, 43, 66, 22, 19, 10, 87, 51, 11, 18, 72, 85, 66, 20, 10, 61, 8, 85, 66, 19, 47, 13, 71, 66, 22, 92, 81, 2, 84, 90, 45, 29, 71, 50, 99, 59, 10, 24, 51, 69, 24, 5, 35, 37, 45, 67, 5, 54, 97, 97, 58, 35, 26, 81, 87, 14, 51, 84, 17, 79, 39, 48, 73, 79, 94, 24, 69, 10, 57, 35, 24, 82, 43, 3, 77, 41, 0, 3, 21, 0, 98, 45, 39, 66, 62, 8, 53, 69, 47, 48, 53, 61, 57, 32, 11, 62, 22, 7, 59, 6, 58, 42, 66, 98, 65, 49, 31, 43, 24, 83, 3, 69, 47, 46, 25, 11, 85, 41, 66, 5, 37, 12, 61, 23, 35, 93, 16, 29, 18, 15, 31, 79, 3, 58, 1, 63, 57, 26, 45, 73, 72, 48, 56, 44, 79, 86, 86, 1, 51, 5, 92, 85, 20, 9, 94, 91, 10, 67, 30, 8, 98, 48, 6, 50, 90, 51, 47, 98, 86, 66, 59, 75, 16, 43, 51, 76, 9, 64, 20, 77, 34, 26, 71, 49, 94, 98, 92, 77, 76, 82, 50, 43, 97, 69, 95, 93, 13, 57, 79, 45, 67, 15, 7, 17, 48, 77, 65, 33, 24, 30, 19, 21, 36, 27, 52, 31, 44, 2, 84, 42, 21, 22, 1, 7, 22, 58, 66, 3, 27, 25, 17, 32, 55, 83, 85, 28, 16, 72, 66, 50, 94, 37, 52, 26, 9, 30, 76, 5, 51, 51, 26, 36, 6, 88, 30]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV7FhT58I0in",
        "outputId": "2f88df1b-01c1-4751-a3be-70f8b6de825c"
      },
      "source": [
        "randomList2 = []\n",
        "# Set a length of the list to 10\n",
        "for i in range(0, list_lenght):\n",
        "    randomList2.append(randint(0, 100))\n",
        "\n",
        "print(\"Segunda lista\",randomList2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segunda lista [82, 44, 48, 26, 6, 66, 43, 88, 30, 9, 36, 83, 4, 16, 56, 35, 75, 82, 9, 77, 82, 26, 27, 11, 93, 8, 36, 96, 0, 90, 54, 95, 70, 86, 39, 59, 83, 41, 55, 44, 98, 9, 65, 80, 83, 11, 52, 57, 9, 95, 39, 14, 73, 34, 90, 19, 13, 70, 74, 36, 58, 5, 61, 88, 29, 61, 89, 46, 41, 97, 15, 42, 96, 70, 35, 90, 49, 61, 77, 98, 56, 15, 80, 16, 38, 7, 63, 87, 57, 50, 17, 11, 64, 27, 9, 29, 85, 75, 26, 78, 16, 61, 87, 85, 35, 75, 63, 88, 18, 61, 38, 52, 85, 91, 38, 93, 65, 22, 67, 71, 0, 20, 9, 84, 68, 78, 37, 81, 96, 71, 63, 5, 35, 65, 55, 16, 86, 15, 56, 63, 74, 98, 81, 7, 90, 37, 52, 80, 10, 95, 97, 78, 65, 23, 40, 10, 2, 45, 14, 73, 41, 78, 18, 81, 15, 8, 80, 71, 61, 50, 27, 11, 10, 93, 84, 27, 2, 77, 64, 81, 14, 52, 57, 93, 76, 14, 17, 42, 57, 41, 26, 61, 81, 59, 60, 39, 2, 58, 8, 11, 58, 4, 83, 66, 8, 13, 52, 39, 7, 77, 64, 93, 26, 4, 6, 21, 78, 37, 77, 77, 92, 98, 96, 95, 62, 76, 10, 63, 24, 62, 29, 62, 83, 21, 55, 45, 72, 43, 36, 87, 22, 79, 39, 13, 7, 98, 55, 54, 10, 64, 93, 34, 86, 5, 14, 26, 0, 34, 3, 36, 8, 62, 43, 17, 8, 1, 43, 77, 93, 92, 34, 88, 77, 85, 9, 3, 16, 96, 82, 26, 35, 17, 38, 59, 24, 77, 23, 0, 17, 26, 41, 71, 46, 32, 12, 65, 20, 97, 25, 48, 34, 85, 70, 67, 21, 74, 32, 11, 43, 96, 34, 17, 17, 97, 75, 51, 56, 34, 66, 69, 20, 73, 28, 42, 52, 42, 33, 67, 74, 40, 27, 52, 4, 13, 29, 21, 43, 45, 46, 36, 37, 22, 74, 87, 97, 44, 43, 17, 15, 63, 48, 5, 41, 98, 65, 83, 81, 58, 0, 45, 51, 30, 18, 0, 47, 40, 28, 31, 48, 46, 55, 89, 38, 99, 74, 99, 75, 94, 46, 71, 41, 67, 42, 15, 87, 4, 36, 10, 42, 92, 83, 98, 64, 16, 32, 66, 73, 38, 89, 15, 17, 77, 83, 76, 27, 50, 44, 6, 28, 18, 81, 70, 39, 0, 30, 13, 28, 51, 83, 70, 0, 43, 24, 77, 89, 43, 18, 29, 70, 72, 98, 6, 48, 31, 59, 73, 61, 5, 27, 16, 33, 40, 91, 42, 38, 76, 9, 26, 29, 72, 47, 37, 73, 84, 63, 40, 68, 91, 15, 68, 46, 74, 33, 48, 97, 46, 38, 92, 51, 58, 81, 60, 19, 6, 35, 32, 99, 47, 81, 19, 32, 99, 35, 28, 34, 59, 15, 4, 0, 87, 8, 75, 6, 10, 18, 19, 16, 51, 49, 33, 93, 71, 24, 36, 89, 44, 80, 43, 59, 48, 91, 27, 72, 47, 65, 30, 54, 7, 87, 21, 43, 23, 72, 49, 12, 49, 77, 89, 93, 19, 11, 41, 31, 83, 69, 60, 91, 63, 71, 3, 90, 73, 16, 67, 73, 87, 75, 96, 17, 74, 3, 32, 99, 13, 69, 23, 65, 52, 85, 43, 0, 79, 44, 77, 81, 55, 35, 3, 9, 1, 75, 49, 53, 70, 8, 89, 74, 82, 48, 70, 93, 12, 60, 49, 27, 7, 10, 42, 27, 46, 10, 80, 10, 29, 59, 53, 61, 4, 28, 39, 90, 39, 20, 24, 0, 93, 87, 86, 98, 47, 66, 99, 79, 61, 95, 2, 19, 94, 23, 66, 19, 91, 37, 71, 40, 9, 7, 45, 93, 4, 57, 91, 40, 0, 31, 98, 81, 71, 63, 13, 22, 33, 46, 56, 59, 65, 72, 86, 19, 37, 16, 97, 66, 58, 29, 37, 85, 30, 70, 64, 0, 86, 95, 92, 92, 66, 48, 63, 85, 13, 46, 50, 35, 71, 6, 58, 91, 35, 35, 10, 31, 20, 68, 48, 87, 28, 75, 46, 51, 36, 59, 1, 61, 52, 70, 43, 74, 56, 7, 25, 19, 93, 0, 91, 80, 25, 8, 26, 10, 40, 36, 8, 58, 95, 70, 10, 25, 37, 17, 34, 41, 37, 85, 25, 90, 56, 34, 4, 98, 35, 33, 53, 65, 37, 52, 7, 43, 42, 87, 15, 95, 43, 6, 21, 24, 10, 99, 58, 51, 47, 80, 8, 29, 60, 15, 1, 64, 59, 54, 61, 57, 54, 49, 13, 73, 76, 79, 85, 61, 58, 99, 14, 8, 80, 33, 58, 57, 61, 74, 44, 83, 80, 43, 92, 5, 23, 69, 30, 35, 70, 42, 64, 0, 44, 52, 61, 3, 31, 80, 91, 94, 20, 74, 96, 56, 24, 63, 3, 95, 80, 46, 17, 75, 59, 67, 45, 97, 51, 45, 61, 53, 75, 9, 6, 22, 18, 1, 69, 50, 46, 76, 13, 4, 95, 83, 51, 11, 51, 97, 30, 20, 28, 84, 85, 41, 39, 9, 34, 18, 41, 43, 63, 15, 5, 62, 27, 76, 96, 98, 39, 93, 24, 79, 75, 45, 79, 53, 31, 24, 58, 97, 92, 53, 41, 41, 73, 15, 79, 68, 39, 68, 58, 35, 89, 84, 44, 13, 23, 93, 84, 85, 25, 65, 89, 75, 12, 36, 38, 15, 89, 1, 19, 62, 73, 11, 84, 67, 31, 15, 27, 56, 72, 57, 27, 90, 37, 79, 43, 29, 3, 61, 7, 86, 37, 44, 65, 32, 29, 28, 28, 15, 25, 84, 51, 89, 83, 68, 31, 96, 6, 43, 88, 77, 18, 11, 48, 71, 54, 46, 29, 24, 65, 82, 30, 7, 0, 18, 39, 29, 92, 7, 19, 24, 31, 94, 48, 61, 70, 98, 21, 1, 63, 89, 12, 15, 14, 41, 66, 58, 82, 32, 52, 72, 50, 98, 99, 67, 45, 4, 15, 72, 1, 76, 51, 67, 86, 9, 40, 88, 23]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBk80KtYbwm0",
        "outputId": "1a1e7d20-db65-440e-916c-69affeb5b51e"
      },
      "source": [
        "randomList3 = []\n",
        "# Set a length of the list to 10\n",
        "for i in range(0, list_lenght):\n",
        "    randomList3.append(randint(0, 100))\n",
        "\n",
        "print(\"Tercera lista\",randomList3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tercera lista [46, 83, 10, 65, 54, 34, 74, 84, 77, 38, 86, 73, 52, 45, 83, 45, 26, 30, 4, 44, 70, 39, 77, 36, 29, 95, 24, 45, 31, 0, 33, 33, 97, 2, 68, 68, 28, 74, 32, 55, 95, 51, 65, 96, 63, 61, 51, 62, 84, 18, 46, 19, 48, 81, 96, 27, 78, 53, 28, 28, 32, 49, 42, 65, 54, 87, 82, 68, 46, 91, 15, 74, 84, 72, 87, 74, 57, 47, 91, 35, 37, 58, 23, 62, 94, 80, 32, 29, 66, 15, 40, 42, 44, 81, 94, 67, 86, 26, 48, 62, 42, 5, 4, 51, 83, 32, 20, 44, 60, 17, 80, 65, 8, 61, 53, 28, 94, 41, 30, 2, 38, 66, 49, 10, 94, 51, 70, 53, 6, 3, 18, 61, 79, 64, 22, 0, 90, 55, 99, 81, 88, 69, 27, 17, 2, 1, 64, 5, 75, 26, 48, 9, 53, 83, 62, 37, 35, 56, 47, 17, 77, 45, 16, 30, 99, 71, 70, 44, 5, 70, 18, 68, 37, 53, 51, 88, 1, 91, 84, 88, 4, 94, 31, 13, 39, 80, 2, 69, 61, 45, 47, 89, 37, 54, 36, 87, 11, 62, 79, 95, 43, 71, 61, 50, 2, 37, 97, 73, 74, 6, 21, 52, 29, 84, 67, 68, 14, 6, 5, 73, 14, 3, 90, 63, 22, 43, 6, 53, 34, 16, 44, 87, 68, 55, 59, 45, 40, 88, 30, 9, 9, 98, 51, 92, 1, 28, 61, 91, 95, 30, 93, 47, 27, 3, 59, 26, 84, 48, 60, 30, 45, 68, 94, 43, 43, 94, 55, 88, 24, 48, 3, 78, 67, 53, 40, 48, 9, 73, 92, 86, 78, 18, 12, 88, 61, 8, 53, 12, 46, 10, 22, 65, 84, 17, 61, 47, 58, 76, 4, 57, 22, 92, 44, 17, 90, 19, 96, 15, 47, 65, 59, 40, 69, 86, 3, 48, 38, 11, 4, 65, 20, 84, 29, 23, 40, 51, 86, 8, 4, 62, 40, 41, 99, 87, 72, 15, 78, 63, 9, 31, 55, 89, 10, 5, 81, 22, 38, 3, 54, 25, 92, 49, 68, 31, 26, 95, 69, 88, 85, 52, 20, 63, 71, 35, 37, 43, 78, 97, 5, 22, 60, 96, 57, 98, 57, 57, 5, 68, 33, 4, 39, 43, 91, 24, 44, 52, 76, 98, 24, 72, 93, 65, 36, 80, 10, 26, 30, 68, 62, 85, 99, 66, 9, 80, 12, 36, 38, 41, 54, 14, 57, 45, 11, 16, 18, 94, 48, 99, 49, 33, 68, 53, 58, 98, 43, 75, 65, 59, 52, 30, 52, 23, 50, 87, 53, 38, 35, 35, 94, 19, 79, 90, 93, 26, 79, 54, 49, 57, 4, 49, 95, 31, 41, 44, 34, 1, 72, 44, 42, 73, 7, 39, 61, 4, 44, 80, 35, 78, 50, 69, 68, 73, 0, 73, 34, 54, 48, 88, 45, 59, 33, 76, 48, 95, 31, 45, 38, 14, 1, 24, 39, 63, 51, 68, 76, 2, 78, 37, 90, 26, 78, 56, 25, 96, 16, 86, 49, 78, 54, 35, 62, 20, 84, 15, 30, 23, 49, 66, 17, 79, 65, 88, 80, 97, 61, 79, 83, 95, 61, 4, 55, 94, 45, 95, 20, 74, 62, 70, 54, 18, 30, 74, 10, 74, 46, 42, 96, 91, 50, 47, 43, 75, 77, 17, 94, 2, 88, 0, 7, 84, 78, 92, 43, 10, 57, 36, 40, 1, 92, 76, 38, 69, 5, 64, 56, 54, 0, 23, 87, 60, 59, 63, 55, 10, 46, 14, 8, 14, 68, 29, 40, 86, 25, 44, 12, 36, 78, 17, 13, 73, 10, 69, 76, 30, 79, 49, 86, 10, 3, 8, 46, 19, 46, 82, 93, 90, 69, 38, 30, 75, 39, 1, 88, 16, 58, 90, 73, 67, 8, 96, 37, 69, 51, 72, 84, 62, 82, 17, 29, 6, 65, 47, 27, 21, 34, 11, 67, 87, 64, 80, 18, 0, 57, 80, 78, 81, 5, 79, 23, 63, 89, 3, 23, 13, 96, 2, 13, 9, 76, 17, 39, 61, 85, 32, 25, 74, 12, 2, 82, 89, 47, 8, 14, 11, 57, 59, 71, 99, 50, 37, 96, 54, 9, 70, 76, 30, 6, 68, 9, 74, 26, 9, 46, 49, 65, 17, 97, 76, 55, 96, 98, 95, 49, 31, 40, 17, 28, 9, 86, 81, 97, 85, 65, 17, 70, 20, 4, 37, 16, 49, 5, 52, 51, 3, 53, 54, 33, 37, 36, 15, 40, 31, 72, 87, 27, 59, 33, 24, 72, 58, 3, 40, 43, 28, 7, 48, 98, 78, 73, 57, 68, 41, 62, 32, 39, 52, 96, 29, 53, 22, 47, 26, 90, 82, 76, 16, 35, 41, 76, 16, 3, 19, 12, 7, 34, 58, 56, 90, 28, 67, 68, 10, 19, 82, 62, 12, 92, 43, 78, 2, 7, 9, 41, 26, 91, 39, 24, 16, 13, 82, 80, 41, 42, 22, 11, 69, 22, 57, 56, 75, 28, 47, 50, 58, 62, 59, 34, 86, 26, 79, 31, 43, 40, 15, 60, 81, 69, 20, 71, 4, 31, 79, 95, 20, 56, 43, 45, 75, 18, 22, 33, 50, 9, 13, 49, 94, 72, 5, 23, 38, 82, 93, 70, 52, 21, 72, 68, 10, 4, 31, 32, 30, 8, 25, 76, 15, 54, 17, 2, 51, 21, 16, 77, 27, 40, 99, 31, 92, 95, 45, 38, 39, 91, 34, 5, 62, 44, 3, 36, 15, 10, 33, 37, 93, 86, 50, 57, 24, 21, 46, 16, 45, 76, 82, 93, 45, 72, 58, 20, 47, 7, 80, 91, 51, 66, 94, 46, 11, 96, 71, 25, 25, 62, 44, 53, 71, 27, 86, 0, 38, 71, 93, 30, 95, 94, 50, 77, 73, 67, 16, 56, 82, 71, 29, 92, 72, 82, 63, 5, 99, 7, 18, 93, 81, 45, 46, 41, 41, 92, 27, 98, 5, 13, 14, 65, 52, 38, 82, 18, 50, 96, 95, 5, 57, 96, 74, 98, 23, 77, 13, 86, 96, 28, 9, 44, 5, 11, 89, 72, 78]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efmzy7zWxXbG",
        "outputId": "b041ef0d-2acc-4499-8bf1-cde411c8713b"
      },
      "source": [
        "randomList4 = []\n",
        "# Set a length of the list to 10\n",
        "for i in range(0, list_lenght):\n",
        "    randomList4.append( randomList2[i] + ([-1,1][randrange(2)]) ) \n",
        "\n",
        "print(\"Cuarta lista\",randomList4)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuarta lista [83, 43, 47, 25, 7, 65, 44, 89, 29, 8, 37, 82, 3, 17, 55, 36, 76, 81, 8, 76, 83, 27, 26, 10, 92, 9, 37, 95, 1, 89, 53, 94, 69, 87, 38, 58, 84, 40, 54, 43, 99, 8, 66, 79, 84, 10, 53, 56, 10, 94, 38, 15, 72, 35, 91, 18, 12, 71, 75, 37, 59, 6, 62, 89, 28, 62, 90, 45, 40, 96, 16, 41, 95, 69, 36, 91, 50, 62, 76, 99, 57, 14, 81, 17, 39, 8, 62, 86, 56, 51, 16, 10, 65, 28, 8, 30, 86, 74, 27, 77, 15, 62, 88, 84, 36, 74, 64, 87, 19, 60, 37, 51, 84, 90, 37, 94, 64, 21, 68, 70, 1, 21, 10, 85, 69, 79, 38, 80, 97, 70, 62, 6, 36, 66, 56, 15, 85, 14, 57, 64, 73, 99, 80, 6, 91, 38, 53, 81, 9, 96, 96, 77, 66, 22, 41, 11, 1, 44, 13, 72, 40, 79, 19, 80, 16, 9, 79, 70, 60, 51, 28, 12, 11, 94, 83, 26, 3, 78, 63, 82, 15, 51, 58, 92, 75, 15, 16, 41, 56, 42, 27, 60, 80, 58, 59, 38, 3, 57, 7, 12, 57, 3, 82, 65, 7, 12, 53, 38, 8, 78, 65, 92, 27, 5, 7, 20, 79, 36, 76, 76, 91, 99, 95, 94, 63, 75, 11, 62, 23, 61, 30, 61, 82, 22, 54, 46, 71, 44, 35, 88, 21, 78, 38, 14, 8, 97, 56, 55, 11, 65, 94, 33, 85, 6, 13, 25, -1, 33, 4, 35, 9, 63, 44, 16, 9, 2, 42, 78, 94, 93, 33, 87, 76, 84, 8, 4, 15, 95, 83, 25, 36, 16, 39, 58, 25, 76, 24, -1, 18, 25, 40, 72, 47, 31, 13, 64, 19, 98, 24, 49, 33, 86, 71, 66, 22, 73, 33, 10, 42, 95, 33, 16, 18, 96, 74, 50, 55, 35, 67, 70, 19, 72, 29, 43, 53, 41, 34, 66, 73, 41, 26, 53, 5, 14, 28, 22, 44, 46, 45, 35, 36, 23, 73, 88, 98, 45, 44, 18, 14, 62, 49, 6, 40, 97, 66, 82, 82, 59, 1, 44, 52, 31, 19, -1, 46, 39, 27, 30, 47, 47, 54, 90, 39, 100, 75, 98, 76, 95, 47, 72, 42, 68, 43, 16, 88, 5, 37, 11, 43, 93, 82, 99, 63, 15, 33, 65, 74, 37, 90, 16, 16, 76, 82, 75, 28, 51, 43, 5, 27, 17, 80, 69, 40, 1, 29, 14, 29, 50, 82, 71, 1, 44, 25, 78, 88, 42, 17, 30, 69, 73, 99, 5, 47, 32, 60, 72, 62, 4, 26, 15, 34, 39, 92, 43, 39, 75, 10, 27, 28, 73, 48, 36, 74, 83, 64, 39, 67, 90, 16, 69, 45, 75, 32, 47, 96, 47, 39, 93, 52, 59, 80, 61, 18, 7, 36, 31, 100, 46, 82, 20, 31, 100, 36, 29, 33, 58, 14, 5, -1, 88, 9, 74, 5, 9, 19, 18, 15, 52, 48, 32, 94, 70, 25, 37, 90, 45, 81, 44, 60, 47, 90, 26, 71, 46, 66, 29, 55, 6, 86, 20, 44, 22, 71, 50, 13, 48, 76, 88, 92, 20, 12, 40, 30, 84, 68, 59, 92, 64, 72, 4, 89, 74, 15, 66, 72, 88, 74, 97, 18, 75, 2, 33, 100, 12, 68, 24, 64, 53, 86, 44, -1, 80, 43, 78, 80, 54, 34, 4, 10, 2, 74, 48, 54, 71, 7, 90, 73, 81, 47, 71, 92, 13, 59, 50, 28, 8, 9, 41, 26, 45, 9, 81, 9, 28, 58, 52, 60, 5, 29, 40, 89, 40, 21, 23, -1, 92, 88, 87, 99, 48, 65, 100, 78, 62, 94, 1, 20, 93, 24, 67, 18, 92, 38, 72, 41, 8, 8, 46, 92, 5, 58, 90, 39, -1, 30, 99, 82, 70, 64, 12, 23, 34, 47, 57, 60, 66, 73, 85, 20, 36, 17, 98, 65, 57, 28, 38, 86, 31, 71, 63, -1, 85, 94, 91, 91, 67, 49, 62, 86, 12, 45, 51, 34, 70, 5, 59, 92, 34, 36, 11, 32, 21, 69, 49, 88, 29, 74, 47, 52, 35, 60, 0, 62, 53, 69, 42, 73, 55, 6, 24, 20, 94, 1, 92, 79, 26, 9, 27, 11, 39, 35, 9, 57, 96, 71, 9, 26, 36, 16, 35, 40, 36, 86, 24, 89, 57, 33, 5, 99, 36, 32, 52, 64, 36, 53, 6, 42, 41, 86, 14, 94, 42, 5, 22, 25, 9, 100, 57, 52, 46, 79, 7, 30, 59, 16, 0, 65, 58, 55, 60, 56, 55, 48, 12, 72, 75, 78, 84, 60, 59, 100, 15, 9, 81, 34, 57, 58, 60, 75, 45, 82, 81, 44, 93, 6, 24, 70, 31, 36, 69, 43, 63, -1, 43, 53, 62, 4, 30, 79, 90, 93, 19, 73, 95, 57, 25, 62, 4, 94, 81, 47, 18, 76, 58, 66, 46, 98, 50, 44, 60, 52, 76, 8, 5, 21, 17, 0, 68, 51, 47, 75, 14, 5, 94, 84, 50, 10, 50, 96, 29, 19, 29, 85, 86, 40, 40, 8, 35, 19, 40, 44, 62, 16, 4, 63, 28, 77, 95, 99, 40, 92, 25, 78, 74, 44, 80, 52, 32, 23, 57, 98, 93, 54, 42, 40, 74, 16, 80, 67, 38, 69, 57, 36, 88, 85, 45, 14, 24, 94, 85, 84, 24, 64, 90, 76, 13, 35, 39, 14, 90, 0, 18, 63, 72, 10, 85, 66, 30, 16, 26, 57, 71, 56, 26, 91, 36, 80, 44, 28, 2, 62, 6, 85, 36, 45, 66, 31, 28, 29, 27, 16, 24, 85, 52, 88, 82, 69, 32, 97, 7, 44, 87, 78, 19, 10, 49, 70, 53, 47, 28, 25, 64, 83, 29, 6, -1, 19, 40, 28, 93, 6, 18, 23, 30, 93, 47, 60, 69, 99, 22, 0, 62, 90, 11, 16, 15, 42, 67, 59, 83, 31, 51, 73, 51, 99, 100, 66, 44, 3, 14, 71, 0, 77, 50, 66, 87, 10, 39, 89, 22]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50312RYeJDRm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94245751-e08e-40e9-ba7a-095b3284f585"
      },
      "source": [
        "randomSum=np.add(randomList1,randomList2)\n",
        "print(randomSum)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[129 127  86  79  82  90  58 137  53  35  66 126  34  42 114 127 144 162\n",
            "  82 124 132 102  64  45 131  75  47  96  75 170  57  97  89  98 104 134\n",
            " 164  55 126 104 144  37 146 167  96 107  64 126 104 126 128  98 118  50\n",
            " 131  91  69 140 130 122 102  95 144 135  78  79 174  92 139 134  53  49\n",
            " 163  75  82 137  64  95  87 126  60  97 169  71 116  30 113 149 112 134\n",
            "  17 109 154  60  30 100 153 156  78 142 101 102  88  99  38 105  75 161\n",
            "  37  87 134 120 149 113  94 177  73  66  91 165  15  92  11 100  70 157\n",
            " 104 127 194 128 118  41 123  98  97  18 173  99  91  81 150 167 162  87\n",
            "  98 112  67 100  26 159 158 174 148  80  89  72  59 128  41 160  76 114\n",
            " 102 142  43   9  91 133  78  80  65 109  35 149 108  39  78 173  72 128\n",
            " 101  77  78 115 121  33  58  89  93  80  43 100 140 141  97 137  89  96\n",
            "  16  65  75  45 130  85  51  57  87  81  27 103 153 116  28  69  95  48\n",
            " 156 105 168 137  95 179 143 156 125 108  23 119  72 120 123  97 140  81\n",
            " 138  54 132  93  87 136  93 160  43  16  95 144 149 101  73 148  98 117\n",
            " 158  77  77  82  14 115 102  96  16 103  76  86  96  64  60  78  94  94\n",
            "  85 165 129 178  23  50  91 161 111  35 131  97  88  76  55 172  97  11\n",
            "  51  79 130 159  70 126 107 120  73 120  83 144  50  91 151 145  78  78\n",
            "  78  86  49 183  52  65  56 113 173 123 102  86 106 114  22 133  48 129\n",
            " 126 118  91  67 116  57  76  68  52  93 110  97 138 108  95  51  62 106\n",
            "  99 156 147  59 127  94  61  80  48  72  78 180  95 109 141 105  67  96\n",
            "  88  34  55  36 127  45  82 121 111 129 131 101  71 184  78 148 121 149\n",
            " 145  90  88 109  90 105 135   6  71  56  75 130 180 165 110  74  69 136\n",
            " 107 108 130  41  27 164 107 149  39 110  45  99  79  24  99 120  84  36\n",
            " 119  59  71 128 138  91  30 121 121 135 124 124  69  77 164 166 100  51\n",
            " 111  31 154  92  66  39  53  31  39 103 175  59 118 163  93  68  55 163\n",
            " 144 131 158 109 107  53 113 145  90 118 140 118 121 122 173  69  48 179\n",
            " 106 118 164  75  49  76  72  86 174 126 137  25  85 172 132  78 108 124\n",
            "  61  69   5 167  10 142  69  50  42  20  83  54 114 107 115 160  37  89\n",
            " 136 108  92 124  78 101 184  68 161 134 121  38  68  11 179  54  96  37\n",
            " 163  92  40 117 147 163 181  26  58 125  59 100 130  67 146 127 102  61\n",
            " 139 165  43 164 103 130 140 185  65  98 100  47 102  39 140 105 112 131\n",
            " 152  93  51 131  93 122 124 122  40  94  43  77 127 131 118 121  65 160\n",
            " 131 169  66  75 116  25 119 127  53 102  31  82  43  62  77 177 105 109\n",
            "  75 145 107  81  96 122 110 104  76  78  40 100 104 165 141  92 105 156\n",
            "  92  62 174   8  40 164  55 158 117 135  73 160  86  63  29 143 142  82\n",
            " 110  96 112  62  85 121 163 133  98  86  84  83 127 105 148 151  83 161\n",
            "  76 103  49 190 159 137 120  45 172 113 142 159  53 134 172 101 101 125\n",
            " 100  76  90  99 123  64  86 127  81  59 130 103 116 103  45  45 163 132\n",
            " 154 101 153  82  79 111 122  17 114 127  90  65 128 123  79  83  78 149\n",
            "  72 104 117  32  17  99  74  48  72  22 150 164 123  92  87  66  87 101\n",
            " 105 125 102 111 116  86  82  23 105  77 108  95 150 127  64 103 115  67\n",
            " 175 106 154 118  55 111  68  62 142 124  73  66  90  95  80  71  33  73\n",
            " 149 125  74  71 118  62 134  79  92 123  92 156 127  80 191  95  10 164\n",
            " 123 103  86 132 124 143 142  90  67 143  74  47  74  65  72 115 109  69\n",
            "  54 141 149 119  38  57 161 178 108  71 158 113 135  63 111  76 174 174\n",
            "  70  86  85 116 102  69 179  94  48 138  94  75  12  27  22 116  46 108\n",
            " 116 108  84  66  73 142 131 104  72 108 129  41  82  50  91 144  47  97\n",
            "  51 100 116 106  92  94  58  29 145  30 145 143 144  64 104 109 120 141\n",
            "  50 116  65  92  47  93 190 108  82  59  56 104  94  82 126  40 131 115\n",
            "  61 134 157 116  61  79 137 163 171 111  66 140  80 104 121  58  24 183\n",
            "  92  29 129 103  19 182 115  37  65 117 107 119 155 113 156  96 154  59\n",
            "  72  54 137  16 150  57 121  99  58 100  77 122 113 117 161 127 171 133\n",
            " 111 128 165 101 136 101 134  97  56 115  86  61  63  77 101 130 115  54\n",
            "  37  19  39  75  56 144  38  63  26 115 136  69  83  71 105  43  59 129\n",
            "  92  39  40  31  73 121 141 167  60  68 144 116 148 193 104  97  30  24\n",
            " 102  77  81 102 118 112  45  46 176  53]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz89pTNvl0le"
      },
      "source": [
        "Se construye un dataframe con las anteriores listas distribuidas en forma de columnas. Los datos tienen tres variables independientes y una dependiente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwm-wJ625XrZ",
        "outputId": "17b3fa46-d2e0-4fce-af87-d5fbe52ecd43"
      },
      "source": [
        "df2=np.column_stack((randomList1, randomList2, randomList3, randomSum))\n",
        "print(df2.shape)\n",
        "dfnew=pd.DataFrame(data=df2)\n",
        "print(dfnew.shape)\n",
        "print(dfnew.columns)\n",
        "dfnew.columns = [\"V1\",\"V2\",\"V3\",\"Output\"]\n",
        "print(dfnew.columns)\n",
        "\n",
        "del(df2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 4)\n",
            "(1000, 4)\n",
            "RangeIndex(start=0, stop=4, step=1)\n",
            "Index(['V1', 'V2', 'V3', 'Output'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J75JEXmKGry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1925acba-9c65-4e83-be55-58b60419babc"
      },
      "source": [
        "print(dfnew)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     V1  V2  V3  Output\n",
            "0    47  82  46     129\n",
            "1    83  44  83     127\n",
            "2    38  48  10      86\n",
            "3    53  26  65      79\n",
            "4    76   6  54      82\n",
            "..   ..  ..  ..     ...\n",
            "995  26  86   5     112\n",
            "996  36   9  11      45\n",
            "997   6  40  89      46\n",
            "998  88  88  72     176\n",
            "999  30  23  78      53\n",
            "\n",
            "[1000 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3YFmUE4lvsH"
      },
      "source": [
        "Se eliminan las variables no necesarias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuLt5jPPmLcS"
      },
      "source": [
        "del(randomList1,randomList2,randomList3,randomSum)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5JDha7BmRD_"
      },
      "source": [
        "A partir del dataframe, se separan las variables independientes (X) y las dependientes (Y)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpxU3-4hKiN2",
        "outputId": "3979d2e2-c830-40be-e101-f2f2e6e5ef00"
      },
      "source": [
        "X = dfnew.iloc[:,0:3]\n",
        "print(X.shape)\n",
        "Y = dfnew.iloc[:,3]\n",
        "print(Y.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 3)\n",
            "(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QGkp0AMLOI_"
      },
      "source": [
        "## Separación de los conjuntos de entrenamiento y test.\n",
        "Se verifica la dimensionalidad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6gM5MQLK68I"
      },
      "source": [
        "# Quality check\n",
        "assert X.shape[0] == Y.shape[0]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGomoPvbQK5y"
      },
      "source": [
        "Se establece que el conjunto de test sea el 30% de los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7z4Y6KaLFaI",
        "outputId": "6e6fae21-38e7-4b56-cf69-c45b3f4c3deb"
      },
      "source": [
        "test_size = int(np.floor(0.30*X.shape[0]) )\n",
        "print(test_size)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxwcduzFQjo1"
      },
      "source": [
        " X = np.asarray(X)# convertirnos los datos de DataFrame a Numpy Arrays\n",
        " Y = np.asarray(Y)# para que sean leidos por los modulos de Keras"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr_h24ndogk4"
      },
      "source": [
        "Se dividen los arrays de las variables independientes y dependientes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vxfjfFuLNDD",
        "outputId": "7ceccb22-f472-40fa-ea29-edb67f0643fc"
      },
      "source": [
        "trainX, testX = X[:-test_size], X[-test_size:]\n",
        "trainY, testY = Y[:-test_size], Y[-test_size:]\n",
        "print(trainX.shape,testX.shape)\n",
        "print(len(trainY),len(testY))\n",
        "\n",
        "trainX_num=trainX.shape[1]\n",
        "print(trainX_num)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(700, 3) (300, 3)\n",
            "700 300\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4G0bP-uonsc"
      },
      "source": [
        "## Definición de la Red Neuronal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhmjlgItQ66v"
      },
      "source": [
        "model = keras.Sequential() # creamos el modelo secuencial\n",
        "\n",
        "# Ponemos una primera capa oculta\n",
        "model.add(Dense(2, activation='relu', input_shape=(trainX.shape[1],))) \n",
        "\n",
        "# Incorporamos la capa de salida\n",
        "model.add(Dense( 1, activation='linear'))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxcl9OKHfvxI"
      },
      "source": [
        "Se compila el modelo, incluyendo la elección del optimizador y del error que se minimizará durante el entrenamiento. A continuación se entrena el modelo, almacenando la información del error en la variable \"history\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6_0STjWcGSA"
      },
      "source": [
        "model.compile(loss='mse', optimizer='adam', metrics=['mse'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2_es52ISayE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0993330-b437-4606-8895-5812dce8ab48"
      },
      "source": [
        "history=model.fit(trainX, trainY, epochs=200, batch_size=32, validation_data=(testX, testY), verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "22/22 [==============================] - 1s 17ms/step - loss: 11699.8047 - mse: 11699.8047 - val_loss: 10981.7129 - val_mse: 10981.7129\n",
            "Epoch 2/200\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 11686.2676 - mse: 11686.2676 - val_loss: 10964.2461 - val_mse: 10964.2461\n",
            "Epoch 3/200\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 11663.4600 - mse: 11663.4600 - val_loss: 10930.0938 - val_mse: 10930.0938\n",
            "Epoch 4/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 11613.3340 - mse: 11613.3340 - val_loss: 10852.0918 - val_mse: 10852.0918\n",
            "Epoch 5/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 11488.0361 - mse: 11488.0361 - val_loss: 10676.4326 - val_mse: 10676.4326\n",
            "Epoch 6/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 11178.5654 - mse: 11178.5654 - val_loss: 10273.9443 - val_mse: 10273.9443\n",
            "Epoch 7/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 10617.0449 - mse: 10617.0449 - val_loss: 9657.1445 - val_mse: 9657.1445\n",
            "Epoch 8/200\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 9884.3369 - mse: 9884.3369 - val_loss: 8936.0566 - val_mse: 8936.0566\n",
            "Epoch 9/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 9081.3262 - mse: 9081.3262 - val_loss: 8173.9766 - val_mse: 8173.9766\n",
            "Epoch 10/200\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 8259.2559 - mse: 8259.2559 - val_loss: 7408.6948 - val_mse: 7408.6948\n",
            "Epoch 11/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 7441.9478 - mse: 7441.9478 - val_loss: 6653.1431 - val_mse: 6653.1431\n",
            "Epoch 12/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 6643.6821 - mse: 6643.6821 - val_loss: 5923.5747 - val_mse: 5923.5747\n",
            "Epoch 13/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 5879.2461 - mse: 5879.2461 - val_loss: 5225.3208 - val_mse: 5225.3208\n",
            "Epoch 14/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 5154.0566 - mse: 5154.0566 - val_loss: 4571.5825 - val_mse: 4571.5825\n",
            "Epoch 15/200\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 4480.6245 - mse: 4480.6245 - val_loss: 3964.2429 - val_mse: 3964.2429\n",
            "Epoch 16/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 3856.1829 - mse: 3856.1829 - val_loss: 3418.4265 - val_mse: 3418.4265\n",
            "Epoch 17/200\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 3303.6445 - mse: 3303.6445 - val_loss: 2919.0347 - val_mse: 2919.0347\n",
            "Epoch 18/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 2805.0835 - mse: 2805.0835 - val_loss: 2484.0061 - val_mse: 2484.0061\n",
            "Epoch 19/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 2375.3062 - mse: 2375.3062 - val_loss: 2104.6724 - val_mse: 2104.6724\n",
            "Epoch 20/200\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 2001.3495 - mse: 2001.3495 - val_loss: 1790.5979 - val_mse: 1790.5979\n",
            "Epoch 21/200\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1691.5524 - mse: 1691.5524 - val_loss: 1527.3174 - val_mse: 1527.3174\n",
            "Epoch 22/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 1436.4302 - mse: 1436.4302 - val_loss: 1310.9845 - val_mse: 1310.9845\n",
            "Epoch 23/200\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1229.8831 - mse: 1229.8831 - val_loss: 1136.6543 - val_mse: 1136.6543\n",
            "Epoch 24/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 1063.6594 - mse: 1063.6594 - val_loss: 1001.8428 - val_mse: 1001.8428\n",
            "Epoch 25/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 937.4662 - mse: 937.4662 - val_loss: 892.4901 - val_mse: 892.4901\n",
            "Epoch 26/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 836.3251 - mse: 836.3251 - val_loss: 811.6982 - val_mse: 811.6982\n",
            "Epoch 27/200\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 762.9915 - mse: 762.9915 - val_loss: 745.2245 - val_mse: 745.2245\n",
            "Epoch 28/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 702.6827 - mse: 702.6827 - val_loss: 697.5175 - val_mse: 697.5175\n",
            "Epoch 29/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 658.6921 - mse: 658.6921 - val_loss: 658.6319 - val_mse: 658.6319\n",
            "Epoch 30/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 623.5538 - mse: 623.5538 - val_loss: 627.3200 - val_mse: 627.3200\n",
            "Epoch 31/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 594.3410 - mse: 594.3410 - val_loss: 602.3788 - val_mse: 602.3788\n",
            "Epoch 32/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 570.8884 - mse: 570.8884 - val_loss: 579.8425 - val_mse: 579.8425\n",
            "Epoch 33/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 550.2719 - mse: 550.2719 - val_loss: 559.8690 - val_mse: 559.8690\n",
            "Epoch 34/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 531.3936 - mse: 531.3936 - val_loss: 542.1005 - val_mse: 542.1005\n",
            "Epoch 35/200\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 514.5325 - mse: 514.5325 - val_loss: 525.0878 - val_mse: 525.0878\n",
            "Epoch 36/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 498.3575 - mse: 498.3575 - val_loss: 508.6855 - val_mse: 508.6855\n",
            "Epoch 37/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 482.9629 - mse: 482.9629 - val_loss: 493.0021 - val_mse: 493.0021\n",
            "Epoch 38/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 467.8411 - mse: 467.8411 - val_loss: 477.6703 - val_mse: 477.6703\n",
            "Epoch 39/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 453.2136 - mse: 453.2136 - val_loss: 462.8681 - val_mse: 462.8681\n",
            "Epoch 40/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 439.0479 - mse: 439.0479 - val_loss: 447.8721 - val_mse: 447.8721\n",
            "Epoch 41/200\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 424.7847 - mse: 424.7847 - val_loss: 433.6971 - val_mse: 433.6971\n",
            "Epoch 42/200\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 411.1636 - mse: 411.1636 - val_loss: 419.1830 - val_mse: 419.1830\n",
            "Epoch 43/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 397.3393 - mse: 397.3393 - val_loss: 405.3687 - val_mse: 405.3687\n",
            "Epoch 44/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 384.0150 - mse: 384.0150 - val_loss: 391.4622 - val_mse: 391.4622\n",
            "Epoch 45/200\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 370.7728 - mse: 370.7728 - val_loss: 377.8933 - val_mse: 377.8933\n",
            "Epoch 46/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 357.7692 - mse: 357.7692 - val_loss: 364.6399 - val_mse: 364.6399\n",
            "Epoch 47/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 345.1604 - mse: 345.1604 - val_loss: 351.3246 - val_mse: 351.3246\n",
            "Epoch 48/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 332.5718 - mse: 332.5718 - val_loss: 338.4335 - val_mse: 338.4335\n",
            "Epoch 49/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 320.2245 - mse: 320.2245 - val_loss: 326.1430 - val_mse: 326.1430\n",
            "Epoch 50/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 308.3488 - mse: 308.3488 - val_loss: 313.7199 - val_mse: 313.7199\n",
            "Epoch 51/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 296.4877 - mse: 296.4877 - val_loss: 301.7263 - val_mse: 301.7263\n",
            "Epoch 52/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 285.1671 - mse: 285.1671 - val_loss: 289.6665 - val_mse: 289.6665\n",
            "Epoch 53/200\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 273.7173 - mse: 273.7173 - val_loss: 278.3190 - val_mse: 278.3190\n",
            "Epoch 54/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 262.8491 - mse: 262.8491 - val_loss: 266.7845 - val_mse: 266.7845\n",
            "Epoch 55/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 251.9645 - mse: 251.9645 - val_loss: 255.9223 - val_mse: 255.9223\n",
            "Epoch 56/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 241.5638 - mse: 241.5638 - val_loss: 245.1697 - val_mse: 245.1697\n",
            "Epoch 57/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 231.3793 - mse: 231.3793 - val_loss: 234.6652 - val_mse: 234.6652\n",
            "Epoch 58/200\n",
            " 1/22 [>.............................] - ETA: 0s - loss: 273.2957 - mse: 273.2957"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xstNWQkDgKqM"
      },
      "source": [
        "De forma ilustrativa se puede contar el número de parámetros entrenables del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se6go8Fdgxls"
      },
      "source": [
        "from keras.utils.layer_utils import count_params\n",
        "\n",
        "trainable_count = count_params(model.trainable_weights)\n",
        "non_trainable_count = count_params(model.non_trainable_weights)\n",
        "print(trainable_count,non_trainable_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOcJQzX2gSpw"
      },
      "source": [
        "El modelo entrenado puede ser salvado. Esto es especialmente útil para modelos que requieren mucho tiempo de entrenamiento. Una vez salvado el modelo entrenado, este puede ser recuperado para hacer nuevos pronósiticos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQyPvNYUg2-n"
      },
      "source": [
        "#model.save('modelo_entrenado.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukGvsp9igjMs"
      },
      "source": [
        "Se pronostican los resultados para el conjunto de test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoZKsYcKg_2C"
      },
      "source": [
        "pred = model.predict(testX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_ZGhniogst4"
      },
      "source": [
        "Se calcula el error cuadrático medio del pronóstico."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T50T59BBhBin"
      },
      "source": [
        "testScoreECM = mean_squared_error(testY, pred)\n",
        "print('ECM: %.4f' % (testScoreECM))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXaUNSfCkvxm"
      },
      "source": [
        "## Visualización de resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1oxu8f9fivM"
      },
      "source": [
        "En la siguiente gráfica se visualiza la evolución del error para el conjunto de entrenamiento y test en función de las épocas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lX4jW4Rgllt"
      },
      "source": [
        "plt.figure(1, figsize=(8,8))\n",
        "plt.plot(history.history['mse'])\n",
        "plt.plot(history.history['val_mse'])\n",
        "\n",
        "plt.yscale(\"log\")\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('épocas')\n",
        "plt.legend(['train', 'test'], loc='upper center')\n",
        "\n",
        "from google.colab import files\n",
        "plt.savefig('loss_MLP.eps')\n",
        "#files.download('loss_MLP.eps') # Descomentar para descargar localmente"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvZl4WxwfH-w"
      },
      "source": [
        "Se verifican los resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3AO4VG5i144"
      },
      "source": [
        "print('V1','V2','\\t\\t','Real','\\t','Pronóstico')\n",
        "for i in range(len(testY)):\n",
        "  print(i, testX[i],'\\t',testY[i],'\\t',pred[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf0iYzKwfKJ1"
      },
      "source": [
        "Cálculo de la importancia de las variables siguiendo el algoritmo de Garson.\n",
        "\n",
        "$RI_x=\\sum_{y=1}^n \\frac{|w_{xy} \\cdot w_{yz}|}{\\sum_{x=1}^m|w_{xy}\\cdot w_{yz}|}$, \n",
        "\n",
        "donde $n$ es el número de neuronas, $m$ es el número de variables, $w_{xy}$ los pesos de las neuronas de la capa oculta, y $w_{yz}$ los pesos de las neuronas de la capa de salida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUrMrt_lFb5w"
      },
      "source": [
        "weight = model.get_weights()\n",
        "print(weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGg9Q9CF0f8G"
      },
      "source": [
        "Los pesos de la capa oculta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhLI2c5GvJXa"
      },
      "source": [
        "model.layers[0].get_weights()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muzmdS-So9kW"
      },
      "source": [
        "model.layers[0].get_weights()[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dP_Mxly0jnj"
      },
      "source": [
        "Los pesos de la capa de salida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct8KS4uNvrQH"
      },
      "source": [
        "model.layers[1].get_weights()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1X4XxYDpV3k"
      },
      "source": [
        "model.layers[1].get_weights()[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr8rTghK0orn"
      },
      "source": [
        "Pequeña manipulación para poder multiplicar las matrices de ambas capas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlLERvXpvvYL"
      },
      "source": [
        "weight0=np.array(model.layers[0].get_weights()[0])\n",
        "print(weight0.shape)\n",
        "print(weight0)\n",
        "weight1=np.array(model.layers[1].get_weights()[0])\n",
        "print(weight1.shape)\n",
        "weight1=np.squeeze(weight1)\n",
        "print(weight1.shape)\n",
        "print(weight1)\n",
        "weight1 = np.diag(weight1)\n",
        "print(weight1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03alAVLQv9DS"
      },
      "source": [
        "cw = np.dot(weight0, weight1)\n",
        "print(cw.shape)\n",
        "print(cw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4LlIavmwhH8"
      },
      "source": [
        "cw_h = abs(cw).sum(axis=0)\n",
        "print(cw_h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "465k_d4owlCo"
      },
      "source": [
        "rc = np.divide(abs(cw), abs(cw_h))\n",
        "print(rc)\n",
        "rc = rc.sum(axis=1)\n",
        "print(rc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSK0q3ev0Kcv"
      },
      "source": [
        " ri = rc / rc.sum()\n",
        " print(ri)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI0TuC_CXYBO"
      },
      "source": [
        "Se muestra gráficamente la importancia de las variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNK3OjT7XYJ4"
      },
      "source": [
        "plt.figure(1, figsize=(8,8))\n",
        "\n",
        "objects = ('V1', 'V2', 'V3')\n",
        "y_pos = np.arange(len(ri))\n",
        "\n",
        "plt.bar(y_pos, ri, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Importancia')\n",
        "plt.xlabel('Variables')\n",
        "plt.title('Algoritmo de Garson')\n",
        "\n",
        "from google.colab import files\n",
        "plt.savefig('Imp_Variables_Garson.eps')\n",
        "#files.download('Imp_Variables_Garson.eps') # Descomentar para descargar localmente"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p48lA0FQ00FT"
      },
      "source": [
        "Cálculo siguiendo el algoritmo de Olden.\n",
        "\n",
        "$RI(x_i) = \\sum_{y=1}^n w_{xy} \\cdot w_{yz}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qFjiJSRW_8y"
      },
      "source": [
        "weight0=np.array(model.layers[0].get_weights()[0])\n",
        "print(weight0.shape)\n",
        "print(weight0)\n",
        "weight1=np.array(model.layers[1].get_weights()[0])\n",
        "print(weight1.shape)\n",
        "weight1=np.squeeze(weight1)\n",
        "print(weight1.shape)\n",
        "print(weight1)\n",
        "weight1 = np.diag(weight1)\n",
        "print(weight1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma_eXvU70zNX"
      },
      "source": [
        "cw = np.dot(weight0, weight1)\n",
        "print(cw.shape)\n",
        "print(cw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15f1RHtB1Qxu"
      },
      "source": [
        "cw_h = cw.sum(axis=1)\n",
        "print(cw_h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IBHCIhgXFol"
      },
      "source": [
        "plt.figure(1, figsize=(8,8))\n",
        "\n",
        "n_variables = ('V1', 'V2', 'V3')\n",
        "y_pos = np.arange(len(n_variables))\n",
        "\n",
        "plt.bar(y_pos, cw_h, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, n_variables)\n",
        "plt.ylabel('Importancia')\n",
        "plt.xlabel('Variables')\n",
        "plt.title('Algoritmo de Olden')\n",
        "\n",
        "from google.colab import files\n",
        "plt.savefig('Imp_Variables_Olden.eps')\n",
        "#files.download('Imp_Variables_Olden.eps') # Descomentar para descargar localmente"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCDXgFRl1fqI"
      },
      "source": [
        "## Propuestas adicionales.\n",
        "\n",
        "*   Modificar el código de forma que sea el pronóstico sea el resultado de la suma de tres variables y además añadir en la entrada una variable adicional que no se suma.\n",
        "\n"
      ]
    }
  ]
}