{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferLearning_VGG16_CatDog.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHK6DyunSbs4"
      },
      "source": [
        "# Transferencia de aprendizaje aplicado a un clasificador de Perros y Gatos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUP7Rp1gWKSe"
      },
      "source": [
        "## Librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnQN0a5P6iCI"
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJvDl__owt13"
      },
      "source": [
        "from tensorflow.keras import layers, applications\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbKxSVEzu2l3"
      },
      "source": [
        "## Explorando los datos\n",
        "Se descargan los datos en un fichero zip con 2000 imágenes de perros y gatos. Se descarga el zip y se extraen el directorio /tmp de la máquina virtual local. Estos datos son un subconjunto de \n",
        "[\"Dogs vs. Cats\" dataset](https://www.kaggle.com/c/dogs-vs-cats/data) disponible en Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXZT2UsyIVe_",
        "outputId": "ab36d335-5714-4296-a09d-638e8cfb70da"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-23 11:59:04--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.128, 142.250.141.128, 74.125.137.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  88.2MB/s    in 0.7s    \n",
            "\n",
            "2021-06-23 11:59:05 (88.2 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLy3pthUS0D2"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-qUPyfO7Qr8"
      },
      "source": [
        "Los contenidos del zip son extraídos en el directorio `/tmp/cats_and_dogs_filtered`, conteniendo los directorios `train` and `validation`, los cuales a su vez contienen los subdirectorios `train` and `validation`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLZKVtE0dSfk"
      },
      "source": [
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuBYtA_Zd8_T"
      },
      "source": [
        "Visualizando los nombres de las imágenes en los diferentes directorios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PIP1rkmeAYS",
        "outputId": "9fc51adb-d935-4c59-cbf6-5c315a7970a8"
      },
      "source": [
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "print(train_cat_fnames[:10])\n",
        "\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "train_dog_fnames.sort()\n",
        "print(train_dog_fnames[:10])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cat.168.jpg', 'cat.197.jpg', 'cat.520.jpg', 'cat.16.jpg', 'cat.876.jpg', 'cat.638.jpg', 'cat.251.jpg', 'cat.204.jpg', 'cat.901.jpg', 'cat.863.jpg']\n",
            "['dog.0.jpg', 'dog.1.jpg', 'dog.10.jpg', 'dog.100.jpg', 'dog.101.jpg', 'dog.102.jpg', 'dog.103.jpg', 'dog.104.jpg', 'dog.105.jpg', 'dog.106.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlqN5KbafhLI"
      },
      "source": [
        "Número total de imágenes en cada categoría y directorio.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4XHh2xSfgie",
        "outputId": "ba7a6d4f-c4b5-4373-9995-bf9f2f7efc18"
      },
      "source": [
        "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
        "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
        "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
        "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training cat images: 1000\n",
            "total training dog images: 1000\n",
            "total validation cat images: 500\n",
            "total validation dog images: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSmqBzpBtbc9"
      },
      "source": [
        "Para gatos y perro hay 1000 imágenes en el entrenamiento y 500 en la validación (test)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDSiD616wdiK"
      },
      "source": [
        "## Creación de un modelo \n",
        "\n",
        "Este modelo se basa en el modelo VGG16.\n",
        "\n",
        "Las imágenes color se escalan a tamaño image_size X image_size píxeles, aunque en realidad son objetos 150x150x3 debido a los 3 colores RGB.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfuDnnXGdT6P"
      },
      "source": [
        "#Se configura el tamaño de las imágenes.\n",
        "image_size=128"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OOOqZI-eead"
      },
      "source": [
        "# Se queréis ver la red VGG16 al completo, descomentad el siguiente par de comandos.\n",
        "# conv_model = applications.VGG16(weights='imagenet', input_shape=(224,224,3) )\n",
        "# conv_model.summary()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8twa4j4dp_2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3439def-6bed-4502-9515-a3b02efd9916"
      },
      "source": [
        "# Se carga la parte convolucional del modelo entrenado VGG16.\n",
        "# Very Deep Convolutional Networks for Large-Scale Image Recognition\n",
        "# Karen Simonyan, Andrew Zisserman\n",
        "# https://arxiv.org/abs/1409.1556\n",
        "\n",
        "conv_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(image_size,image_size,3) )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTDZKz2ZpMEr",
        "outputId": "4f4b87a6-1daf-41e1-9a38-ea31cc007010"
      },
      "source": [
        "conv_model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IBJzyw-ptLT"
      },
      "source": [
        "# Se añaden una capa flatten,\n",
        "x = layers.Flatten()(conv_model.output)\n",
        "# varias capas densas \n",
        "# (a medida que se añadan más capas densas el tiempo de entrenamiento se incrementa)\n",
        "x = layers.Dense(10, activation='relu')(x)\n",
        "#x = layers.Dense(100, activation='relu')(x)\n",
        "#x = layers.Dense(100, activation='relu')(x)\n",
        "# y una capa final softmax \n",
        "predictions = layers.Dense(2, activation='softmax', name='dense_output')(x)\n",
        "# puesto que nuestro problema es un clasificador binario (gatos-perros)\n",
        "# la capa de salida debe tener dos neuronas con softmax como función de activación."
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycGZjjZLqzpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d40e324-17a9-4358-8e55-6383fce646c2"
      },
      "source": [
        "# Crear el modelo completo\n",
        "full_model = Model(inputs=conv_model.input, outputs=predictions)\n",
        "full_model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                81930     \n",
            "_________________________________________________________________\n",
            "dense_output (Dense)         (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 14,796,640\n",
            "Trainable params: 14,796,640\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5dt0ExzrWbl"
      },
      "source": [
        "# Bloquear el entrenamiento de todas las capas de la parte convolucional\n",
        "for layer in conv_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljO0Mdh6syrQ",
        "outputId": "17701f55-7018-4195-cca3-a894cbe4e77a"
      },
      "source": [
        "# Imprimir el número total de parámetros del modelo completo, \n",
        "# separando los entrenables de los no entrenables.\n",
        "from keras.utils.layer_utils import count_params\n",
        "trainable_count = count_params(full_model.trainable_weights) \n",
        "non_trainable_count = count_params(full_model.non_trainable_weights) \n",
        "  \n",
        "print('Parámetros totales: {:,}'.format(trainable_count + non_trainable_count)) \n",
        "print('Parámetros entrenables: {:,}'.format(trainable_count)) "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parámetros totales: 14,796,640\n",
            "Parámetros entrenables: 81,952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kyh0LL6Gruaq",
        "outputId": "bf842fe8-3de4-4b0d-bd8f-48151d9e6e9e"
      },
      "source": [
        "# Se comprueba la estructura del modelo completo\n",
        "full_model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                81930     \n",
            "_________________________________________________________________\n",
            "dense_output (Dense)         (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 14,796,640\n",
            "Trainable params: 81,952\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH37tWIXxEk4"
      },
      "source": [
        "# Entrenar el modelo.\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "full_model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=0.001),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClebU9NJg99G",
        "outputId": "9e0afce8-0d64-4cab-d258-a6b44bf1ed87"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Se reescala la intensidad de las imágenes en un factor 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flujo de imágenes de entramiento en grupos de 32 \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  \n",
        "        target_size=(image_size, image_size),  \n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Flujo de imágenes de validación o test en grupo de 32 \n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AiUvcQwzBlS"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdHCkcFdg102",
        "outputId": "fccb1cf6-c918-4f84-fe58-eb725c223782"
      },
      "source": [
        "history=full_model.fit(\n",
        "    train_generator, \n",
        "    epochs=3, \n",
        "    batch_size=32, \n",
        "    validation_data=validation_generator, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "34/63 [===============>..............] - ETA: 1:37 - loss: 0.7148 - acc: 0.5746"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F2wmF7XzMb2"
      },
      "source": [
        "## Evaluar la calidad del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex8BmcXqMR6Q"
      },
      "source": [
        "### Error y exactitud.\n",
        "Se representan el error y la exactitud para los conjuntos de entrenamiento y validación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oj0gTIy4k60"
      },
      "source": [
        "# Retrieve a list of accuracy results on training and validation data\n",
        "# sets for each training epoch\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "# Retrieve a list of list results on training and validation data\n",
        "# sets for each training epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(acc))\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc)\n",
        "plt.plot(epochs, val_acc)\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss)\n",
        "plt.plot(epochs, val_loss)\n",
        "plt.title('Training and validation loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItuRcZeoK6k5"
      },
      "source": [
        "Y_pred = full_model.predict(validation_generator) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGOUKxdvx3d9"
      },
      "source": [
        "# Ejemplo de pronóstico y su clase real.\n",
        "print('Pronóstico:',Y_pred[0], ', y clase original: ',validation_generator.labels[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDmLzxV52TQ8"
      },
      "source": [
        "# Visualización de los pronósticos.\n",
        "plt.figure(1,figsize=(6,6)) \n",
        "plt.style.use('seaborn-deep') \n",
        "plt.hist(-Y_pred[:500,0],50,histtype='step',color='darkorange', label= \"Gatos\")\n",
        "plt.hist(Y_pred[500:,1],50,histtype='step',color='blue', label= \"Perros\")\n",
        "plt.ylabel('Número de casos')\n",
        "plt.xlabel('Predicción')\n",
        "plt.title(\"Clasificador CNN Perros-Gatos\")\n",
        "plt.xlim(-1.01,1.01)\n",
        "plt.legend( loc='upper center')\n",
        "\n",
        "from google.colab import files\n",
        "plt.savefig('ClasificadorCNNVGG16PerrosGatos.eps')\n",
        "files.download('ClasificadorCNNVGG16PerrosGatos.eps') # Descomentar para descargar localmente"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfRo0ayQ0EbD"
      },
      "source": [
        "## Propuestas adicionales.\n",
        "\n",
        "*   Si se compara con nuestra anterior propuesta de clasificador ¿Mejora la clasificación de perros y gatos con el uso de transferencia de aprendizaje a partir de una red VGG16?\n",
        "*   Probar a mejorar la clasificación con otras redes preentrenadas:\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
        "\n",
        "\n"
      ]
    }
  ]
}